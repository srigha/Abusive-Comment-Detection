{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h9NYkvo_56xy",
        "5UCX8miNaTVE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShriDurga17/Machine-Learning/blob/main/AbusiveCommentDetection(Train_models).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuBQFnO_w1Yl",
        "outputId": "9b44b21f-9937-4ae0-c0e0-c792af40356b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to convert emojis to text\n",
        "!pip install emot\n",
        "!pip install xgboost\n",
        "!pip install Textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSGkTrukxjCo",
        "outputId": "3ad4e369-39fd-4759-da56-e41c76418c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emot\n",
            "  Downloading emot-3.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emot\n",
            "Successfully installed emot-3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from Textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import string"
      ],
      "metadata": {
        "id": "Itxe_4Ofxsgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import gc\n",
        "import os\n",
        "import fileinput\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import datetime\n",
        "import sys\n",
        "from tqdm  import tqdm\n",
        "tqdm.pandas()\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score"
      ],
      "metadata": {
        "id": "VELObUjSxwIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "btadbmZWxzdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skmultilearn.ensemble import MajorityVotingClassifier\n",
        "from skmultilearn.cluster import FixedLabelSpaceClusterer\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "F5TZQ6UTx2lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import  CountVectorizer, TfidfTransformer,TfidfVectorizer\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "v7eXd8A4x5ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "metadata": {
        "id": "tOD9P5i_x8vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "WX_oLN84zhZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMPORTING DATASETS\n"
      ],
      "metadata": {
        "id": "XzFPt3fix-fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/ta-misogyny-train (1).csv')"
      ],
      "metadata": {
        "id": "pISw6q-Xy2ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Q-VqIVBu11",
        "outputId": "3a9f8e16-84c9-4773-df5c-72de03c49af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2239, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev=pd.read_csv('/content/ta-misogyny-dev.csv')"
      ],
      "metadata": {
        "id": "Syg5vKCry9Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev.shape"
      ],
      "metadata": {
        "id": "Fv1TRoCdCJxz",
        "outputId": "2ab8cf03-f5a0-4cf1-ae61-5d7d5d9c0ee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(559, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev[['Category','Cont']] = df.Content.str.split(\"\\t\",expand=True)"
      ],
      "metadata": {
        "id": "YnSwVZRJzGxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev=dev[['Category','Cont']]"
      ],
      "metadata": {
        "id": "OFYnyfHWzW8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Category','Cont']] = df.Content.str.split(\"\\t\",expand=True)"
      ],
      "metadata": {
        "id": "lit6k3YfzZtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[['Category','Cont']]"
      ],
      "metadata": {
        "id": "ARS6WrHdzcQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=df"
      ],
      "metadata": {
        "id": "_lQ6HPNFzeVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.read_csv('/content/tamil_test_without_labels.csv')"
      ],
      "metadata": {
        "id": "Htj7xA-ZKNCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VALUE COUNT"
      ],
      "metadata": {
        "id": "3OhbaebFzgXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.mask(lambda x: x['Category'] == 'Not-Tamil')\n",
        "df_filtered = data.mask(lambda x: x['Category'] == 'Not-Tamil')"
      ],
      "metadata": {
        "id": "EaOXbAbPzj4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZruHcxpPznZm",
        "outputId": "2a2ca8d5-9a8d-411c-f1c2-d05b38e77d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "None-of-the-above    1296\n",
              "Misandry              446\n",
              "Counter-speech        149\n",
              "Misogyny              125\n",
              "Xenophobia             95\n",
              "Hope-Speech            85\n",
              "Homophobia             35\n",
              "Transphobic             6\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLEAN TEXT IMPORT"
      ],
      "metadata": {
        "id": "NDJSuCMhzp8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install clean-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2SgS3KMzsy8",
        "outputId": "5377c5fe-f109-48dd-df22-e38b18dfc170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting clean-text\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting emoji<2.0.0,>=1.0.0 (from clean-text)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.6)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=f867e2fe16b7911c35e6e48bec66ac3ff52e7a35eb56c24e1c7b26033f3bfd16\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, ftfy, clean-text\n",
            "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import reuters\n",
        "from nltk.corpus import brown\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import SnowballStemmer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import pickle\n",
        "import joblib\n",
        "from collections import Counter\n",
        "from textblob import Word\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, f1_score, recall_score\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Activation, Dense, Embedding, LSTM, SpatialDropout1D, Dropout, Flatten, GRU, Conv1D, MaxPooling1D, Bidirectional\n",
        "from wordcloud import WordCloud,ImageColorGenerator\n",
        "from PIL import Image\n",
        "import urllib\n",
        "import requests\n",
        "import re\n",
        "!pip install ktrain\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('brown')\n",
        "nltk.download(\"reuters\")\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6hn8TZdu371",
        "outputId": "bde60827-d0ca-48be-9b1e-ae7b212c79da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ktrain\n",
            "  Downloading ktrain-0.37.0.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.5.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.27.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (23.1)\n",
            "Collecting langdetect (from ktrain)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet (from ktrain)\n",
            "  Downloading cchardet-2.1.7.tar.gz (653 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.6/653.6 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.0.0)\n",
            "Collecting syntok>1.3.3 (from ktrain)\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika (from ktrain)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers>=4.17.0 (from ktrain)\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from ktrain)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0 (from ktrain)\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh (from ktrain)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.22.4)\n",
            "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2022.7.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.17.0->ktrain)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.17.0->ktrain)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, cchardet, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.37.0-py3-none-any.whl size=25320561 sha256=386346b5b7761ab6a2df3f146bfc19a24c61000ffd070fe827874ce24c23a0f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/b5/c4/9a0db005c3c6df396364011cb05305505592d9d48ee177a606\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33501 sha256=a0419988bc60681817d601a590fff9d31ed6e8222992fbc8fd790cefb2b97b68\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12287 sha256=87cb244e9670cf2fc0fbf53d163b9010d4105de29228f8a4fb489f4dfd7c32a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3943 sha256=c4150497266700a5b0aed9a9769392cce588fa1a009233047989b507009703fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4653 sha256=5fc8caff3091415a900013155552237bdb97bbfb2028e3dd3135d94044bdaf90\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14979 sha256=8878ee3dadedffe2b85e48aa4f23aedf755b9ca3c5df51aab74fc76a1e0a4079\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6946 sha256=89b879bf0bc97beb5ea2d9ab9a2399e50d2fab6d1d6f18d31ca8f5f995ea8761\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4968 sha256=a64c4dfff9573edc3962785fb9a4f1db4dfa222e856d450c73e6bced72043d83\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=09f1ced3101466fcdc016a9e8357e851c2714848b73f15738657baaff593a1f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for cchardet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cchardet: filename=cchardet-2.1.7-cp310-cp310-linux_x86_64.whl size=261587 sha256=1005060b57b23c54c6192aef69fbb380d687b283f32a389e7a902f1e9240b4d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/e0/ab/e01326f15c59438d080b1496dbab8091e952ec72f35e3c437e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=afd55b7224cb8e62794b9858765cd7ca804ddd0f95f2741c21c6fd347b6add5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32625 sha256=1fda269e1c788682d07fcbfd324d33647c5e5a11939445dd111b3d33da4c2706\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention cchardet langdetect tika\n",
            "Installing collected packages: whoosh, tokenizers, sentencepiece, cchardet, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, huggingface-hub, transformers, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed cchardet-2.1.7 huggingface-hub-0.14.1 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.37.0 langdetect-1.0.9 sentencepiece-0.1.99 syntok-1.4.4 tika-2.6.0 tokenizers-0.13.3 transformers-4.29.2 whoosh-2.7.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleantext import clean"
      ],
      "metadata": {
        "id": "dhZLESXgzxs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd95d3dd-c6c3-44b4-ffbf-f3b134a4dbe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA CLEANING"
      ],
      "metadata": {
        "id": "mFrCVjMKz1eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean'] = df_filtered['Cont'].apply(lambda x:clean(x))\n",
        "data.head()\n",
        "\n",
        "\n",
        "dev['clean'] = dev['Cont'].apply(lambda x:clean(x))\n",
        "dev.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_MUqHixhz5j4",
        "outputId": "d7bdb58f-4234-45be-b136-ae81cf50d9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Category                                               Cont  \\\n",
              "0  None-of-the-above  எச். ராசாவால் இராமருக்கே  இழிவு. இவர் எல்லாம் ...   \n",
              "1  None-of-the-above  கல்யாணம்னு  வரும்போது தான் சாதி முக்கியம் எங்க...   \n",
              "2  None-of-the-above                 Tentu Kottai ஐயா நான் தமிழ் இந்து.   \n",
              "3         Homophobia  Tamil selvan  அடே தேவடியாவுக்கு பிரந்தவனே பச்ச...   \n",
              "4  None-of-the-above  bro நீங்க பேசறதெல்லாம் கேக்க கேக்க இரவு துக்கம...   \n",
              "\n",
              "                               clean  \n",
              "0                              . . .  \n",
              "1                                     \n",
              "2                     tentu kottai .  \n",
              "3  tamil selvan ... . tamil selva...  \n",
              "4                                bro  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-908ad0ac-082f-4d9c-9c6b-1e38d056aeeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Cont</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None-of-the-above</td>\n",
              "      <td>எச். ராசாவால் இராமருக்கே  இழிவு. இவர் எல்லாம் ...</td>\n",
              "      <td>. . .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None-of-the-above</td>\n",
              "      <td>கல்யாணம்னு  வரும்போது தான் சாதி முக்கியம் எங்க...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None-of-the-above</td>\n",
              "      <td>Tentu Kottai ஐயா நான் தமிழ் இந்து.</td>\n",
              "      <td>tentu kottai .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Homophobia</td>\n",
              "      <td>Tamil selvan  அடே தேவடியாவுக்கு பிரந்தவனே பச்ச...</td>\n",
              "      <td>tamil selvan ... . tamil selva...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None-of-the-above</td>\n",
              "      <td>bro நீங்க பேசறதெல்லாம் கேக்க கேக்க இரவு துக்கம...</td>\n",
              "      <td>bro</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-908ad0ac-082f-4d9c-9c6b-1e38d056aeeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-908ad0ac-082f-4d9c-9c6b-1e38d056aeeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-908ad0ac-082f-4d9c-9c6b-1e38d056aeeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=data['Category']\n",
        "y_train=df_filtered['Category']\n",
        "y_test=dev['Category']\n",
        "\n",
        "\n",
        "y = pd.get_dummies(df_filtered['Category']).values\n",
        "\n",
        "\n",
        "y_train1=pd.get_dummies(y_train).values\n",
        "y_test1=pd.get_dummies(y_test).values\n",
        "diz_label = {}\n",
        "for i,Category in enumerate(df_filtered.Category.factorize()[1]):\n",
        "    diz_label[i] = Category\n",
        "\n",
        "diz_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDDL8nMTz8Nd",
        "outputId": "ad10a1b8-ffee-4ce4-d8c6-dfe6563129d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'None-of-the-above',\n",
              " 1: 'Homophobia',\n",
              " 2: 'Misandry',\n",
              " 3: 'Counter-speech',\n",
              " 4: 'Misogyny',\n",
              " 5: 'Xenophobia',\n",
              " 6: 'Transphobic',\n",
              " 7: 'Hope-Speech'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "KsuOW7RY19yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train=data"
      ],
      "metadata": {
        "id": "rfrs2MtD3X5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect = CountVectorizer()\n",
        "cv_vect= count_vect.fit(data_train[\"Cont\"])\n",
        "cv_vect_train= count_vect.transform(data_train[\"Cont\"])\n",
        "cv_vect_test= count_vect.transform(dev[\"Cont\"])\n",
        "\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_tfidf = tfidf_transformer.fit(cv_vect_train)\n",
        "X_tfidf_train = tfidf_transformer.transform(cv_vect_train)\n",
        "X_tfidf_test = tfidf_transformer.transform(cv_vect_test)"
      ],
      "metadata": {
        "id": "XeXCeJlp2CzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE"
      ],
      "metadata": {
        "id": "kv6HX_-53eTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "\n",
        "strategy = {0:3720, 1:3720, 2:3720, 3:3720, 4:3720, 5:3720,6:3720,7:3720}\n",
        "oversample = SMOTE(sampling_strategy=strategy)\n",
        "X_train, y_train = oversample.fit_resample(X_tfidf_train, y_train1)"
      ],
      "metadata": {
        "id": "JMgMRVuD3iPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "zqeQeOTw3vMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3))\n",
        "tfidf_vect_ngram_chars.fit(data['clean'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(data['clean'])\n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(dev['clean'])\n",
        "\n"
      ],
      "metadata": {
        "id": "XIveD68K4H6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MACHINE LEARNING"
      ],
      "metadata": {
        "id": "XPtQgawf4Zhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decicion Tree"
      ],
      "metadata": {
        "id": "lr8DZsUW4dXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(xtrain_tfidf_ngram_chars,y_train1, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Oy1VfVlkj6-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "modeld = tree.DecisionTreeClassifier()\n",
        "modeld.fit(X_train,y_train)\n",
        "y_predd=modeld.predict(X_test)"
      ],
      "metadata": {
        "id": "L8hq6OW3kPS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_predd))\n",
        "print(confusion_matrix(y_test.argmax(axis=1),y_predd.argmax(axis=1)) )\n",
        "accuracy = accuracy_score(y_test,y_predd)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yewQntGkgGa",
        "outputId": "f89eb244-bf01-426b-9d2c-17bf981c082b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.24      0.31        29\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00        12\n",
            "           3       0.28      0.07      0.11       104\n",
            "           4       0.25      0.11      0.15        27\n",
            "           5       0.61      0.85      0.71       256\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00        12\n",
            "\n",
            "   micro avg       0.56      0.52      0.54       447\n",
            "   macro avg       0.20      0.16      0.16       447\n",
            "weighted avg       0.46      0.52      0.46       447\n",
            " samples avg       0.52      0.52      0.52       447\n",
            "\n",
            "[[ 10   0   0   1   1  17   0   1]\n",
            " [  1   0   0   0   0   4   0   1]\n",
            " [  0   0   0   1   0  11   0   0]\n",
            " [ 10   0   2   7   0  84   1   0]\n",
            " [  7   0   0   1   3  16   0   0]\n",
            " [ 18   0   0  13   7 217   0   1]\n",
            " [  1   0   0   0   0   0   0   0]\n",
            " [  1   0   0   2   1   8   0   0]]\n",
            "Test Accuracy: 52.4554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "5bshzynUrxuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "modelrf = RandomForestClassifier()\n",
        "modelrf.fit(X_train,y_train)\n",
        "y_predrf=modelrf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_predrf))\n",
        "print(confusion_matrix(y_test.argmax(axis=1),y_predrf.argmax(axis=1)) )\n",
        "accuracy = accuracy_score(y_test,y_predrf)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSCmxBnHk0W1",
        "outputId": "0901d2a3-ff87-442b-d7f0-5125b6579650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.10      0.17        29\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00        12\n",
            "           3       0.43      0.03      0.05       104\n",
            "           4       0.25      0.04      0.06        27\n",
            "           5       0.60      0.89      0.72       256\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00        12\n",
            "\n",
            "   micro avg       0.59      0.52      0.55       447\n",
            "   macro avg       0.21      0.13      0.13       447\n",
            "weighted avg       0.49      0.52      0.44       447\n",
            " samples avg       0.52      0.52      0.52       447\n",
            "\n",
            "[[ 10   0   0   0   0  20   0   0]\n",
            " [  1   0   0   0   0   5   0   0]\n",
            " [  1   0   0   0   0  11   0   0]\n",
            " [ 11   0   2   3   2  86   0   0]\n",
            " [  9   0   0   0   1  17   0   0]\n",
            " [ 26   0   0   2   1 227   0   0]\n",
            " [  0   0   0   1   0   0   0   0]\n",
            " [  0   0   0   1   0  11   0   0]]\n",
            "Test Accuracy: 52.4554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "cft7lSYLsD9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "modelkn=KNeighborsClassifier(n_neighbors=5)\n",
        "modelkn.fit(X_train,y_train)\n",
        "y_predkn=modelkn.predict(X_test)\n",
        "\n",
        "\n",
        "print(classification_report(y_test,y_predkn))\n",
        "print(confusion_matrix(y_test.argmax(axis=1),y_predkn.argmax(axis=1)) )\n",
        "accuracy = accuracy_score(y_test,y_predkn)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_VFBho0lQaL",
        "outputId": "04498395-f7be-4bcf-c6d1-4c273ccfd1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.10      0.17        29\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00        12\n",
            "           3       0.25      0.03      0.05       104\n",
            "           4       1.00      0.07      0.14        27\n",
            "           5       0.62      0.86      0.72       256\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00        12\n",
            "\n",
            "   micro avg       0.61      0.51      0.55       447\n",
            "   macro avg       0.30      0.13      0.14       447\n",
            "weighted avg       0.51      0.51      0.44       447\n",
            " samples avg       0.51      0.51      0.51       447\n",
            "\n",
            "[[  9   0   0   0   0  21   0   0]\n",
            " [  1   0   0   0   0   5   0   0]\n",
            " [  0   0   0   2   0  10   0   0]\n",
            " [ 26   0   0   3   0  75   0   0]\n",
            " [  9   0   0   0   2  16   0   0]\n",
            " [ 30   0   0   6   0 220   0   0]\n",
            " [  0   0   0   1   0   0   0   0]\n",
            " [  4   0   0   0   0   8   0   0]]\n",
            "Test Accuracy: 50.8929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XG Boost"
      ],
      "metadata": {
        "id": "OCu_O0ClsPiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "modelxg = XGBClassifier()\n",
        "modelxg.fit(X_train,y_train)\n",
        "y_predxg=modelxg.predict(X_test)\n",
        "\n",
        "\n",
        "print(classification_report(y_test,y_predxg))\n",
        "print(confusion_matrix(y_test.argmax(axis=1),y_predxg.argmax(axis=1)) )\n",
        "accuracy = accuracy_score(y_test,y_predxg)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "410uiwMvl3Lx",
        "outputId": "a3e48bdf-2066-40bf-d3ae-0fe06e46bf99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.17      0.24        29\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00        12\n",
            "           3       0.50      0.07      0.12       104\n",
            "           4       1.00      0.07      0.14        27\n",
            "           5       0.61      0.86      0.71       256\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00        12\n",
            "\n",
            "   micro avg       0.59      0.52      0.56       447\n",
            "   macro avg       0.31      0.15      0.15       447\n",
            "weighted avg       0.55      0.52      0.46       447\n",
            " samples avg       0.51      0.52      0.52       447\n",
            "\n",
            "[[ 13   0   0   0   0  17   0   0]\n",
            " [  0   0   0   0   0   6   0   0]\n",
            " [  3   0   0   0   0   9   0   0]\n",
            " [ 14   0   2   7   0  80   0   1]\n",
            " [ 11   0   0   1   2  13   0   0]\n",
            " [ 33   0   1   4   0 217   0   1]\n",
            " [  0   0   0   1   0   0   0   0]\n",
            " [  2   0   0   1   0   9   0   0]]\n",
            "Test Accuracy: 50.8929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df[\"Cont\"],df[\"Category\"], test_size = 0.25, random_state = 42)\n",
        "count_vect = CountVectorizer(ngram_range=(1, 2))\n",
        "transformer = TfidfTransformer(norm='l2',sublinear_tf=True)\n",
        "x_train_counts = count_vect.fit_transform(x_train)\n",
        "x_train_tfidf = transformer.fit_transform(x_train_counts)\n",
        "\n",
        "x_test_counts = count_vect.transform(x_test)\n",
        "x_test_tfidf = transformer.transform(x_test_counts)\n",
        "\n",
        "print (x_train_tfidf.shape,x_test_tfidf.shape, y_train.shape, y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYuXxxwHsqes",
        "outputId": "32f90f7c-241e-4fe2-b271-8ea784878edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1679, 11765) (560, 11765) (1679,) (560,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(count_vect, 'count_vect.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3efjRtlVt6iI",
        "outputId": "6d0c6acc-7b09-4738-fdbb-29711bc5ddcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['count_vect.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(n_estimators=300, max_depth=15, random_state=42, class_weight='balanced')\n",
        "rfc.fit(x_train_tfidf,y_train)\n",
        "y_pred4 = rfc.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_test,y_pred4)))\n",
        "print(classification_report(y_test, y_pred4))\n",
        "print(confusion_matrix(y_test, y_pred4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niRPPlKTuKMj",
        "outputId": "6ca502ab-3149-4513-a166-2ed755461a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5732142857142857\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   Counter-speech       0.41      0.29      0.34        38\n",
            "       Homophobia       0.28      0.62      0.38         8\n",
            "      Hope-Speech       0.29      0.13      0.18        15\n",
            "         Misandry       0.49      0.57      0.53       129\n",
            "         Misogyny       0.32      0.29      0.30        28\n",
            "None-of-the-above       0.73      0.66      0.69       323\n",
            "        Not-Tamil       0.00      0.00      0.00         1\n",
            "      Transphobic       0.00      0.00      0.00         1\n",
            "       Xenophobia       0.22      0.47      0.30        17\n",
            "\n",
            "         accuracy                           0.57       560\n",
            "        macro avg       0.30      0.34      0.30       560\n",
            "     weighted avg       0.60      0.57      0.58       560\n",
            "\n",
            "[[ 11   0   0   2   1  20   0   0   4]\n",
            " [  0   5   0   3   0   0   0   0   0]\n",
            " [  0   0   2   0   0  13   0   0   0]\n",
            " [  1   6   0  74   8  31   0   2   7]\n",
            " [  2   2   0   4   8   9   0   2   1]\n",
            " [ 13   4   5  65   7 213   0   0  16]\n",
            " [  0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   1   0   3   1   4   0   0   8]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
        "lr.fit(x_train_tfidf, y_train)\n",
        "y_pred1 = lr.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_test,y_pred1)))\n",
        "print(classification_report(y_test, y_pred1))\n",
        "print(confusion_matrix(y_test, y_pred1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN1vVnayuVBA",
        "outputId": "4601fc79-5a43-49ad-b765-bb1262600b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6803571428571429\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   Counter-speech       0.75      0.08      0.14        38\n",
            "       Homophobia       1.00      0.38      0.55         8\n",
            "      Hope-Speech       0.00      0.00      0.00        15\n",
            "         Misandry       0.71      0.47      0.57       129\n",
            "         Misogyny       0.75      0.21      0.33        28\n",
            "None-of-the-above       0.68      0.95      0.79       323\n",
            "        Not-Tamil       0.00      0.00      0.00         1\n",
            "      Transphobic       0.00      0.00      0.00         1\n",
            "       Xenophobia       0.00      0.00      0.00        17\n",
            "\n",
            "         accuracy                           0.68       560\n",
            "        macro avg       0.43      0.23      0.26       560\n",
            "     weighted avg       0.66      0.68      0.62       560\n",
            "\n",
            "[[  3   0   0   0   0  34   0   0   1]\n",
            " [  0   3   0   4   0   1   0   0   0]\n",
            " [  0   0   0   0   0  15   0   0   0]\n",
            " [  0   0   0  61   2  64   0   0   2]\n",
            " [  0   0   0   4   6  18   0   0   0]\n",
            " [  1   0   0  12   0 308   0   0   2]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   5   0  12   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svc = LinearSVC()\n",
        "svc.fit(x_train_tfidf, y_train)\n",
        "y_pred2 = svc.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_test,y_pred2)))\n",
        "print(classification_report(y_test, y_pred2))\n",
        "print(confusion_matrix(y_test, y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EG1TivTvWgc",
        "outputId": "d1d4eb7c-acb4-4507-d23d-a39746abe55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6696428571428571\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   Counter-speech       0.26      0.16      0.20        38\n",
            "       Homophobia       0.50      0.62      0.56         8\n",
            "      Hope-Speech       0.40      0.13      0.20        15\n",
            "         Misandry       0.68      0.51      0.58       129\n",
            "         Misogyny       0.53      0.32      0.40        28\n",
            "None-of-the-above       0.72      0.89      0.79       323\n",
            "        Not-Tamil       0.00      0.00      0.00         1\n",
            "      Transphobic       0.00      0.00      0.00         1\n",
            "       Xenophobia       0.11      0.06      0.08        17\n",
            "\n",
            "         accuracy                           0.67       560\n",
            "        macro avg       0.36      0.30      0.31       560\n",
            "     weighted avg       0.64      0.67      0.64       560\n",
            "\n",
            "[[  6   0   0   0   0  31   0   0   1]\n",
            " [  0   5   0   3   0   0   0   0   0]\n",
            " [  0   0   2   0   0  13   0   0   0]\n",
            " [  3   2   1  66   7  46   0   0   4]\n",
            " [  2   1   0   5   9  11   0   0   0]\n",
            " [ 12   0   2  19   1 286   0   0   3]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   2   0   4   0  10   0   0   1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(x_train_tfidf, y_train)\n",
        "y_pred3 = mnb.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_test,y_pred3)))\n",
        "print(classification_report(y_test, y_pred3))\n",
        "print(confusion_matrix(y_test, y_pred3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zp0ZqncvcmN",
        "outputId": "639ad13d-7d5e-4887-e379-16fb92dcb203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5964285714285714\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   Counter-speech       0.00      0.00      0.00        38\n",
            "       Homophobia       0.00      0.00      0.00         8\n",
            "      Hope-Speech       0.00      0.00      0.00        15\n",
            "         Misandry       0.81      0.10      0.18       129\n",
            "         Misogyny       0.00      0.00      0.00        28\n",
            "None-of-the-above       0.59      0.99      0.74       323\n",
            "        Not-Tamil       0.00      0.00      0.00         1\n",
            "      Transphobic       0.00      0.00      0.00         1\n",
            "       Xenophobia       0.00      0.00      0.00        17\n",
            "\n",
            "         accuracy                           0.60       560\n",
            "        macro avg       0.16      0.12      0.10       560\n",
            "     weighted avg       0.53      0.60      0.47       560\n",
            "\n",
            "[[  0   0   0   0   0  38   0   0   0]\n",
            " [  0   0   0   0   0   8   0   0   0]\n",
            " [  0   0   0   0   0  15   0   0   0]\n",
            " [  0   0   0  13   0 116   0   0   0]\n",
            " [  0   0   0   1   0  27   0   0   0]\n",
            " [  0   0   0   2   0 321   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0  17   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbc = GradientBoostingClassifier(n_estimators=100, max_features='auto', max_depth=4, random_state=1, verbose=1)\n",
        "gbc.fit(x_train_tfidf, y_train)\n",
        "y_pred5 = gbc.predict(x_test_tfidf)\n",
        "print(accuracy_score(y_test, y_pred5))\n",
        "print(classification_report(y_test, y_pred5))\n",
        "print(confusion_matrix(y_test, y_pred5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QHz-RcSvjbm",
        "outputId": "34ae2c33-feac-4158-e5f2-aa69a1452b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1470            1.03m\n",
            "         2           1.0787            1.08m\n",
            "         3           1.0258            1.09m\n",
            "         4           0.9823            1.09m\n",
            "         5           0.9473            1.06m\n",
            "         6           0.9177            1.05m\n",
            "         7           0.8856            1.03m\n",
            "         8           0.8577           58.94s\n",
            "         9           0.8332           55.47s\n",
            "        10           0.8058           52.62s\n",
            "        20           0.6360           38.27s\n",
            "        30           0.5628           28.26s\n",
            "        40           0.5131           21.08s\n",
            "        50           0.4718           16.46s\n",
            "        60           0.4359           12.97s\n",
            "        70           0.4084            9.23s\n",
            "        80           0.3842            5.86s\n",
            "        90           0.3627            2.82s\n",
            "       100           0.3438            0.00s\n",
            "0.6803571428571429\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   Counter-speech       0.50      0.21      0.30        38\n",
            "       Homophobia       0.50      0.62      0.56         8\n",
            "      Hope-Speech       0.17      0.07      0.10        15\n",
            "         Misandry       0.65      0.49      0.56       129\n",
            "         Misogyny       0.50      0.29      0.36        28\n",
            "None-of-the-above       0.72      0.90      0.80       323\n",
            "        Not-Tamil       0.00      0.00      0.00         1\n",
            "      Transphobic       0.00      0.00      0.00         1\n",
            "       Xenophobia       0.46      0.35      0.40        17\n",
            "\n",
            "         accuracy                           0.68       560\n",
            "        macro avg       0.39      0.33      0.34       560\n",
            "     weighted avg       0.65      0.68      0.65       560\n",
            "\n",
            "[[  8   0   0   2   1  24   0   0   3]\n",
            " [  0   5   0   3   0   0   0   0   0]\n",
            " [  0   0   1   0   0  14   0   0   0]\n",
            " [  1   2   2  63   4  53   0   0   4]\n",
            " [  1   1   0   5   8  13   0   0   0]\n",
            " [  6   0   2  22   3 290   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0]\n",
            " [  0   2   0   2   0   7   0   0   6]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnb = MultinomialNB()\n",
        "rfc= RandomForestClassifier(n_estimators=1000, max_depth=12, random_state=42)\n",
        "lr = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
        "svc = SVC(probability=True)\n",
        "ec=VotingClassifier(estimators=[('Multinominal NB', mnb), ('Random Forest', rfc),('Logistic Regression',lr),('Support Vector Machine',svc)], voting='soft', weights=[1,2,3,4])\n",
        "ec.fit(x_train_tfidf,y_train)\n",
        "y_pred6 = ec.predict(x_test_tfidf)\n",
        "print(accuracy_score(y_test, y_pred6))\n",
        "print(classification_report(y_test, y_pred6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Z-V1bwvnIu",
        "outputId": "d26641f3-4712-4d10-e1be-7cc3ba22d919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6875\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   Counter-speech       0.56      0.13      0.21        38\n",
            "       Homophobia       0.57      0.50      0.53         8\n",
            "      Hope-Speech       0.00      0.00      0.00        15\n",
            "         Misandry       0.77      0.47      0.59       129\n",
            "         Misogyny       0.58      0.25      0.35        28\n",
            "None-of-the-above       0.69      0.94      0.80       323\n",
            "        Not-Tamil       0.00      0.00      0.00         1\n",
            "      Transphobic       0.00      0.00      0.00         1\n",
            "       Xenophobia       0.27      0.18      0.21        17\n",
            "\n",
            "         accuracy                           0.69       560\n",
            "        macro avg       0.38      0.28      0.30       560\n",
            "     weighted avg       0.66      0.69      0.64       560\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(n_estimators=100, max_depth=9, random_state=0)\n",
        "abc= AdaBoostClassifier(base_estimator=rfc, learning_rate=0.2, n_estimators=100)\n",
        "abc.fit(x_train_tfidf, y_train)\n",
        "y_pred7= abc.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_test, y_pred7)))\n",
        "print(classification_report(y_test, y_pred7))\n",
        "print(confusion_matrix(y_test, y_pred7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1doCVaOBvv27",
        "outputId": "955973de-9f57-4f74-eba9-bd55fd7ebce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6428571428571429\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   Counter-speech       1.00      0.03      0.05        38\n",
            "       Homophobia       0.00      0.00      0.00         8\n",
            "      Hope-Speech       0.00      0.00      0.00        15\n",
            "         Misandry       0.74      0.30      0.43       129\n",
            "         Misogyny       0.75      0.11      0.19        28\n",
            "None-of-the-above       0.63      0.98      0.77       323\n",
            "        Not-Tamil       0.00      0.00      0.00         1\n",
            "      Transphobic       0.00      0.00      0.00         1\n",
            "       Xenophobia       0.00      0.00      0.00        17\n",
            "\n",
            "         accuracy                           0.64       560\n",
            "        macro avg       0.35      0.16      0.16       560\n",
            "     weighted avg       0.64      0.64      0.55       560\n",
            "\n",
            "[[  1   0   0   0   0  37   0   0   0]\n",
            " [  0   0   0   4   1   3   0   0   0]\n",
            " [  0   0   0   0   0  15   0   0   0]\n",
            " [  0   0   0  39   0  90   0   0   0]\n",
            " [  0   0   0   3   3  22   0   0   0]\n",
            " [  0   0   0   6   0 317   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   1   0  16   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Comparison_unibi = pd.DataFrame({'Logistic Regression': [accuracy_score(y_test,y_pred1)*100,f1_score(y_test,y_pred1,average='macro')*100,recall_score(y_test, y_pred1,average='micro')*100,precision_score(y_test, y_pred1,average='micro')*100],\n",
        "                            'SVM':[accuracy_score(y_test,y_pred2)*100,f1_score(y_test,y_pred2,average='macro')*100,recall_score(y_test, y_pred2,average='micro')*100,precision_score(y_test, y_pred2,average='micro')*100],\n",
        "                           'Naive Bayes':[accuracy_score(y_test,y_pred3)*100,f1_score(y_test,y_pred3,average='macro')*100,recall_score(y_test, y_pred3,average='micro')*100,precision_score(y_test, y_pred3,average='micro')*100],\n",
        "                           'Random Forest':[accuracy_score(y_test,y_pred4)*100,f1_score(y_test,y_pred4,average='macro')*100,recall_score(y_test, y_pred4,average='micro')*100,precision_score(y_test, y_pred4,average='micro')*100],\n",
        "                           'GradientBoosting':[accuracy_score(y_test,y_pred5)*100,f1_score(y_test,y_pred5,average='macro')*100,recall_score(y_test, y_pred5,average='micro')*100,precision_score(y_test, y_pred5,average='micro')*100],\n",
        "                           'Ensembled':[accuracy_score(y_test,y_pred6)*100,f1_score(y_test,y_pred6,average='macro')*100,recall_score(y_test, y_pred6,average='micro')*100,precision_score(y_test, y_pred6,average='micro')*100],\n",
        "                           'Adaboost':[accuracy_score(y_test,y_pred7)*100,f1_score(y_test,y_pred7,average='macro')*100,recall_score(y_test, y_pred7,average='micro')*100,precision_score(y_test, y_pred7,average='micro')*100],\n",
        "\n",
        "})"
      ],
      "metadata": {
        "id": "rkqBAThFv6Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print ('Comparison using uni-bi-gram(1,2)')\n",
        "Comparison_unibi.rename(index={0:'Accuracy',1:'F1_score', 2: 'Recall',3:'Precision'}, inplace=True)\n",
        "Comparison_unibi.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "J-C6i7KSwJYb",
        "outputId": "0a024dc2-2802-4574-ad9e-a97e5506dabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison using uni-bi-gram(1,2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Logistic Regression        SVM  Naive Bayes  Random Forest  \\\n",
              "Accuracy             68.035714  66.964286    59.642857      57.321429   \n",
              "F1_score             26.465330  31.172383    10.219942      30.324113   \n",
              "Recall               68.035714  66.964286    59.642857      57.321429   \n",
              "Precision            68.035714  66.964286    59.642857      57.321429   \n",
              "\n",
              "           GradientBoosting  Ensembled   Adaboost  \n",
              "Accuracy          68.035714  68.750000  64.285714  \n",
              "F1_score          34.091649  29.936768  15.953759  \n",
              "Recall            68.035714  68.750000  64.285714  \n",
              "Precision         68.035714  68.750000  64.285714  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-049856a6-69cc-4192-b438-69d13e969f59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>SVM</th>\n",
              "      <th>Naive Bayes</th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>GradientBoosting</th>\n",
              "      <th>Ensembled</th>\n",
              "      <th>Adaboost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>68.035714</td>\n",
              "      <td>66.964286</td>\n",
              "      <td>59.642857</td>\n",
              "      <td>57.321429</td>\n",
              "      <td>68.035714</td>\n",
              "      <td>68.750000</td>\n",
              "      <td>64.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_score</th>\n",
              "      <td>26.465330</td>\n",
              "      <td>31.172383</td>\n",
              "      <td>10.219942</td>\n",
              "      <td>30.324113</td>\n",
              "      <td>34.091649</td>\n",
              "      <td>29.936768</td>\n",
              "      <td>15.953759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>68.035714</td>\n",
              "      <td>66.964286</td>\n",
              "      <td>59.642857</td>\n",
              "      <td>57.321429</td>\n",
              "      <td>68.035714</td>\n",
              "      <td>68.750000</td>\n",
              "      <td>64.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>68.035714</td>\n",
              "      <td>66.964286</td>\n",
              "      <td>59.642857</td>\n",
              "      <td>57.321429</td>\n",
              "      <td>68.035714</td>\n",
              "      <td>68.750000</td>\n",
              "      <td>64.285714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-049856a6-69cc-4192-b438-69d13e969f59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-049856a6-69cc-4192-b438-69d13e969f59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-049856a6-69cc-4192-b438-69d13e969f59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ],
      "metadata": {
        "id": "wnIl1nmFXTam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert Model"
      ],
      "metadata": {
        "id": "cy-UcFF3W9yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['Cont'], df['Category'], test_size=0.33, random_state=42)\n"
      ],
      "metadata": {
        "id": "Diwba9HZ9NhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = X_train.tolist()\n",
        "X_test = X_test.tolist()\n",
        "y_train = y_train.tolist()\n",
        "y_test = y_test.tolist()"
      ],
      "metadata": {
        "id": "hxbvpi7e9c9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['None-of-the-above','Homophobia','Misandry','Counter-speech','Misogyny','Xenophobia','Transphobic','Hope-Speech','Not-Tamil']"
      ],
      "metadata": {
        "id": "1bsRYGWW9pCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train), (x_val,y_val), preproc = text.texts_from_array(x_train=X_train, y_train=y_train,\n",
        "                                                                       x_test=X_test, y_test=y_test,\n",
        "                                                                       class_names=class_names,\n",
        "                                                                       preprocess_mode='bert',\n",
        "                                                                       maxlen=512,\n",
        "                                                                       max_features=20000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "QSMfkSoB-lt-",
        "outputId": "8ec9110d-d1de-4223-ea3b-624f85101234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing train...\n",
            "language: ta\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: ta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ktrain/utils.py:744: UserWarning: class_names argument was ignored, as they were extracted from string labels in dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "task: text classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = text.text_classifier('bert', train_data=(x_train,y_train), preproc=preproc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0BmdQmv-zcr",
        "outputId": "ef968c23-d5cd-434c-db9c-8da537ccd99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner = ktrain.get_learner(model, train_data=(x_train,y_train),\n",
        "                             val_data=(x_val,y_val),\n",
        "                             batch_size=3)\n"
      ],
      "metadata": {
        "id": "j1Ac-ZYO-55f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.fit_onecycle(2e-5, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMjK17Yf_Di4",
        "outputId": "1c8db6d4-6ca5-4f81-8c47-237db2644267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/3\n",
            "  3/500 [..............................] - ETA: 3:24:53 - loss: 2.5687 - accuracy: 0.0000e+00"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.validate(val_data=(x_val,y_val), class_names=class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhac6hcoDc81",
        "outputId": "9673a9f5-7cb0-4c1c-cf95-69f5786f6572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 34s 1s/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "None-of-the-above       0.33      0.04      0.07        54\n",
            "       Homophobia       0.00      0.00      0.00         8\n",
            "         Misandry       0.00      0.00      0.00        27\n",
            "   Counter-speech       0.54      0.62      0.58       156\n",
            "         Misogyny       0.70      0.18      0.29        39\n",
            "       Xenophobia       0.71      0.88      0.79       431\n",
            "      Transphobic       0.00      0.00      0.00         1\n",
            "      Hope-Speech       0.00      0.00      0.00         1\n",
            "        Not-Tamil       0.00      0.00      0.00        22\n",
            "\n",
            "         accuracy                           0.66       739\n",
            "        macro avg       0.25      0.19      0.19       739\n",
            "     weighted avg       0.59      0.66      0.60       739\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  2,   0,   0,   4,   1,  47,   0,   0,   0],\n",
              "       [  0,   0,   0,   8,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   3,   0,  24,   0,   0,   0],\n",
              "       [  1,   1,   0,  97,   0,  57,   0,   0,   0],\n",
              "       [  2,   2,   0,  12,   7,  16,   0,   0,   0],\n",
              "       [  1,   2,   0,  45,   2, 381,   0,   0,   0],\n",
              "       [  0,   0,   0,   1,   0,   0,   0,   0,   0],\n",
              "       [  0,   1,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,  10,   0,  12,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "h9NYkvo_56xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 15000\n",
        "max_text_len = 768\n",
        "stemmer = SnowballStemmer('english')\n",
        "stop_words = [word for word in stopwords.words('english') if word not in [\"my\",\"haven't\",\"aren't\",\"can\",\"no\", \"why\", \"through\", \"herself\", \"she\", \"he\", \"himself\", \"you\", \"you're\", \"myself\", \"not\", \"here\", \"some\", \"do\", \"does\", \"did\", \"will\", \"don't\", \"doesn't\", \"didn't\", \"won't\", \"should\", \"should've\", \"couldn't\", \"mightn't\", \"mustn't\", \"shouldn't\", \"hadn't\", \"wasn't\", \"wouldn't\"]]\n",
        "\n"
      ],
      "metadata": {
        "id": "JOTID5R656P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "\n",
        "    words = text.lower().split()\n",
        "\n",
        "    words = [stemmer.stem(word) for word in words if not word in stop_words]\n",
        "\n",
        "    cleaned_text = ' '.join(words)\n",
        "    return cleaned_text\n",
        "\n",
        "df['cleaned_text'] = df['Cont'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "rsp4tpV36G54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
        "tokenizer.fit_on_texts(df['cleaned_text'].values)\n",
        "le = len(tokenizer.word_index) + 1\n",
        "print(le)\n",
        "sequences = tokenizer.texts_to_sequences(df['cleaned_text'].values)\n",
        "X_DeepLearning = pad_sequences(sequences, maxlen=max_text_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEmHUrOF6QCr",
        "outputId": "47b98beb-c378-4f3f-e5c4-5093046fb22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['Category'] == 'Counter-speech' , 'LABEL'] = 0\n",
        "df.loc[df['Category'] == 'Homophobia', 'LABEL'] = 1\n",
        "df.loc[df['Category'] == 'Hope-Speech' , 'LABEL'] = 2\n",
        "df.loc[df['Category'] == 'Misandry', 'LABEL'] = 3\n",
        "df.loc[df['Category'] == 'Misogyny', 'LABEL'] = 4\n",
        "df.loc[df['Category'] == 'None-of-the-above', 'LABEL'] = 5\n",
        "df.loc[df['Category'] == 'Transphobic', 'LABEL'] = 6\n",
        "df.loc[df['Category'] == 'Xenophobia', 'LABEL'] = 7\n",
        "df.loc[df['Category'] == 'Not-Tamil', 'LABEL'] = 8\n",
        "\n",
        "labels = to_categorical(df['LABEL'], num_classes=9)\n",
        "XX_train, XX_test, y_train, y_test = train_test_split(X_DeepLearning , labels, test_size=0.25, random_state=42)\n",
        "print((XX_train.shape, y_train.shape, XX_test.shape, y_test.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXszx3JE6TtB",
        "outputId": "771cef5d-4153-494a-9e73-3a4cb2b9d091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((1679, 768), (1679, 9), (560, 768), (560, 9))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "emb_dim = 256\n",
        "batch_size = 50\n",
        "model_lstm1 = Sequential()\n",
        "model_lstm1.add(Embedding(vocabulary_size,emb_dim, input_length=X_DeepLearning.shape[1]))\n",
        "model_lstm1.add(SpatialDropout1D(0.8))\n",
        "model_lstm1.add(Bidirectional(LSTM(300, dropout=0.5, recurrent_dropout=0.5)))\n",
        "model_lstm1.add(Dropout(0.5))\n",
        "model_lstm1.add(Flatten())\n",
        "model_lstm1.add(Dense(64, activation='relu'))\n",
        "model_lstm1.add(Dropout(0.5))\n",
        "model_lstm1.add(Dense(9, activation='softmax'))\n",
        "model_lstm1.compile(optimizer=tf.optimizers.Adam(),loss='categorical_crossentropy', metrics=['acc'])\n",
        "print(model_lstm1.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKqTutK57oeS",
        "outputId": "c256d9bc-e827-4e5e-8c81-1b8c2337a6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 768, 256)          3840000   \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 768, 256)         0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 600)              1336800   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 600)               0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 600)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                38464     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 9)                 585       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,215,849\n",
            "Trainable params: 5,215,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(filepath=\"lastm-1-layer-best_model.h5\", save_best_only=True, monitor=\"val_acc\", mode=\"max\", verbose=1)\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "reduce_lr_callback = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, verbose=1, mode=\"min\", min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "\n",
        "callbacks=[checkpoint_callback, early_stopping_callback, reduce_lr_callback]\n"
      ],
      "metadata": {
        "id": "hCxl5HpO7t9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm1 = model_lstm1.fit(XX_train, y_train, epochs = epochs, batch_size = batch_size, validation_data=(XX_test,y_test), callbacks=callbacks)\n"
      ],
      "metadata": {
        "id": "oCZeS42V7zSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "5UCX8miNaTVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['Cont'], df['Category'], test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "q28ZTvILIyIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "y_test = le.fit_transform(y_test)\n",
        "y_train=le.fit_transform(y_train)"
      ],
      "metadata": {
        "id": "PIK69lFq1bif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgCyDH9paQ2y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcpK3nCuWpd9"
      },
      "outputs": [],
      "source": [
        "vocabulary_size = 25000\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_train1 = pad_sequences(sequences, maxlen=500)\n",
        "sequences = tokenizer.texts_to_sequences(X_test)\n",
        "X_test1 = pad_sequences(sequences, maxlen=500)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaZkVYs6Xnu_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpfUr_QRXdQu"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(20000, 1000, input_length=500))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(64, 2, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(8, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlhWGRQ7YYY6"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxSa48jwYh5c"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DJGsV9rYk52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5d9fcb-3263-41ce-f255-91b0488ebe5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 41s 6s/step - loss: 1.8265 - accuracy: 0.5481 - val_loss: 1.3926 - val_accuracy: 0.5867\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 37s 6s/step - loss: 1.3815 - accuracy: 0.5948 - val_loss: 1.3526 - val_accuracy: 0.5867\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 42s 7s/step - loss: 1.2988 - accuracy: 0.5948 - val_loss: 1.3342 - val_accuracy: 0.5867\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 36s 6s/step - loss: 1.2704 - accuracy: 0.5948 - val_loss: 1.3290 - val_accuracy: 0.5867\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 39s 6s/step - loss: 1.2316 - accuracy: 0.5948 - val_loss: 1.3235 - val_accuracy: 0.5867\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 37s 6s/step - loss: 1.1766 - accuracy: 0.6156 - val_loss: 1.3325 - val_accuracy: 0.5867\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 38s 6s/step - loss: 1.0659 - accuracy: 0.6526 - val_loss: 1.3500 - val_accuracy: 0.5733\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 38s 6s/step - loss: 0.9005 - accuracy: 0.7207 - val_loss: 1.3941 - val_accuracy: 0.5400\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 37s 6s/step - loss: 0.7176 - accuracy: 0.7652 - val_loss: 1.5048 - val_accuracy: 0.5400\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 39s 6s/step - loss: 0.5657 - accuracy: 0.8215 - val_loss: 1.7142 - val_accuracy: 0.5133\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 37s 6s/step - loss: 0.4555 - accuracy: 0.8615 - val_loss: 1.9075 - val_accuracy: 0.4933\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 39s 6s/step - loss: 0.3782 - accuracy: 0.8770 - val_loss: 2.0838 - val_accuracy: 0.4733\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 39s 7s/step - loss: 0.3209 - accuracy: 0.9230 - val_loss: 2.2692 - val_accuracy: 0.3800\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 37s 6s/step - loss: 0.2561 - accuracy: 0.9430 - val_loss: 2.4025 - val_accuracy: 0.4200\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 38s 6s/step - loss: 0.2048 - accuracy: 0.9541 - val_loss: 2.4818 - val_accuracy: 0.3933\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.1567 - accuracy: 0.9674 - val_loss: 2.5967 - val_accuracy: 0.3800\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 39s 6s/step - loss: 0.1220 - accuracy: 0.9763 - val_loss: 2.6237 - val_accuracy: 0.4000\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 38s 6s/step - loss: 0.0961 - accuracy: 0.9800 - val_loss: 2.6898 - val_accuracy: 0.3800\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 37s 6s/step - loss: 0.0805 - accuracy: 0.9822 - val_loss: 2.6973 - val_accuracy: 0.3933\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 38s 6s/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 2.7264 - val_accuracy: 0.4000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f857ef0f7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "model.fit(X_train1, y_train1,batch_size=254,epochs=20,verbose=1,validation_split=0.1,)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ7no7rbwMJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "111003fa-c02f-450c-dc3c-acef832e69d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 4s 169ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoxoTkhcvzUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da048bd1-4d8d-4ec2-f7e5-1dbd7c7e0b73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        54\n",
            "           1       0.00      0.00      0.00         8\n",
            "           2       0.00      0.00      0.00        27\n",
            "           3       0.27      0.23      0.25       156\n",
            "           4       0.07      0.03      0.04        39\n",
            "           5       0.61      0.77      0.68       431\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00        22\n",
            "\n",
            "    accuracy                           0.50       739\n",
            "   macro avg       0.11      0.11      0.11       739\n",
            "weighted avg       0.41      0.50      0.45       739\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pred=np.argmax(preds,axis=1)\n",
        "print(classification_report(y_test,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqB-kdRBwCLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a83ab4-cdb7-4604-bfb3-5aa93e85a6b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0  14   2  38   0   0   0]\n",
            " [  1   0   0   4   0   3   0   0   0]\n",
            " [  1   0   0   2   0  24   0   0   0]\n",
            " [  6   0   1  36   3 105   0   5   0]\n",
            " [  1   0   1   9   1  26   0   1   0]\n",
            " [ 10   0   5  63   8 331   0  14   0]\n",
            " [  0   0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   1   0   0   0   0]\n",
            " [  0   0   0   4   0  18   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "pred=np.argmax(preds,axis=1)\n",
        "print(confusion_matrix(y_test,pred))"
      ]
    }
  ]
}