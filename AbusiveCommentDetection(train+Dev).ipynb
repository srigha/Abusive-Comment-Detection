{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShriDurga17/Abusive-Comment-Detection/blob/main/AbusiveCommentDetection(train%2BDev).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Packages"
      ],
      "metadata": {
        "id": "JLWh7ms3IEn2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQXxkngErMD3",
        "outputId": "67788f71-ec90-4079-a6eb-d5601e04c646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpo9Z2JArWGz",
        "outputId": "eb7a1df4-7e8f-4eed-9fae-9508889bc48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emot\n",
            "  Downloading emot-3.1-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emot\n",
            "Successfully installed emot-3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from Textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->Textblob) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "# to convert emojis to text\n",
        "!pip install emot\n",
        "!pip install xgboost\n",
        "!pip install Textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3w5HTXx87E-"
      },
      "outputs": [],
      "source": [
        "import nltk.data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, f1_score, recall_score\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Activation, Dense, Embedding, LSTM, SpatialDropout1D, Dropout, Flatten, GRU, Conv1D, MaxPooling1D, Bidirectional\n",
        "import requests\n",
        "import re\n",
        "!pip install ktrain\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('brown')\n",
        "nltk.download(\"reuters\")\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqG12g1dyVeL",
        "outputId": "e0946af6-f29e-40ea-ddfa-9ecb8a0c708d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ktrain\n",
            "  Downloading ktrain-0.37.0.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.5.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.27.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (23.1)\n",
            "Collecting langdetect (from ktrain)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet (from ktrain)\n",
            "  Downloading cchardet-2.1.7.tar.gz (653 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.6/653.6 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.0.0)\n",
            "Collecting syntok>1.3.3 (from ktrain)\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika (from ktrain)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers>=4.17.0 (from ktrain)\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from ktrain)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0 (from ktrain)\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh (from ktrain)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.22.4)\n",
            "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2022.7.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.17.0->ktrain)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.17.0->ktrain)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, cchardet, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.37.0-py3-none-any.whl size=25320561 sha256=5313a268a3a026ff99b73a34e77f91f73f409c745748c7189be39ca4a654ef1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/b5/c4/9a0db005c3c6df396364011cb05305505592d9d48ee177a606\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33501 sha256=a4b227cdc93e1693d3c05d92380079caa1672ce7aeedabde535535560859018e\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12287 sha256=2b036233ef65fec138e49a6c17496de986f5948d33af3cfa647cba5ab556dac7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3943 sha256=9e8c63a511c5bc849e801b5c8a5a594f0a88e7b3a08a327199cd5a405c38e468\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4653 sha256=c2add5174433758d4f56aa3c05f7672a5e11b58ceb5b1454fab4f573941b47aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14979 sha256=bcc755742785ceeed7dbbdc1e3936815ae328baaa26cdd2fead7e67bb5fb4cff\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6946 sha256=ad39d9eb05f55350468be4ab501d4b407c7562323d306d6c5705e030d70024f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4968 sha256=8764313f05f95f6c29ca77a1b6fb4a51c3b53b1c24a6b5b1f1aa055991187c56\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=f56f893ea66ea9482525e4a803afb0b332dcd63e26d031874922458e9c896e6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for cchardet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cchardet: filename=cchardet-2.1.7-cp310-cp310-linux_x86_64.whl size=261555 sha256=f8b6d2d4ce9744cb3bb19c3c4d17b5789b46946a7afcb210b3976ce97623dced\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/e0/ab/e01326f15c59438d080b1496dbab8091e952ec72f35e3c437e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=b2afdd25cfaf6218e3d1740b0764ca116b65589e24be21cb00218f4f83ed5c68\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32625 sha256=87aa472cc56e860d8240ab8c6d013560461f8f6ceb189a69a04b98c35d6708d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention cchardet langdetect tika\n",
            "Installing collected packages: whoosh, tokenizers, sentencepiece, cchardet, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, huggingface-hub, transformers, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed cchardet-2.1.7 huggingface-hub-0.14.1 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.37.0 langdetect-1.0.9 sentencepiece-0.1.99 syntok-1.4.4 tika-2.6.0 tokenizers-0.13.3 transformers-4.29.2 whoosh-2.7.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXR_ycdmFlOo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import gc\n",
        "import os\n",
        "import fileinput\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import datetime\n",
        "import sys\n",
        "from tqdm  import tqdm\n",
        "tqdm.pandas()\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0DocYM1FnRe"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkkeEpMAF1Hq"
      },
      "outputs": [],
      "source": [
        "from skmultilearn.ensemble import MajorityVotingClassifier\n",
        "from skmultilearn.cluster import FixedLabelSpaceClusterer\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUH7u2xAF_9T"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import  CountVectorizer, TfidfTransformer,TfidfVectorizer\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from textblob import TextBlob\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n"
      ],
      "metadata": {
        "id": "FT7roG-sJeJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing The Datasets"
      ],
      "metadata": {
        "id": "YO6q_5f9IUdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCYKWuNh9FZu"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/ta-misogyny-train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYhCFoBCyVcw"
      },
      "outputs": [],
      "source": [
        "dev=pd.read_csv('/content/ta-misogyny-dev.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u1JRH2iy48m"
      },
      "outputs": [],
      "source": [
        "dev[['Category','Cont']] = df.Content.str.split(\"\\t\",expand=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1kFtJ1qziFB"
      },
      "outputs": [],
      "source": [
        "dev=dev[['Category','Cont']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKGkbdA2D2LL"
      },
      "outputs": [],
      "source": [
        "df[['Category','Cont']] = df.Content.str.split(\"\\t\",expand=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBz_DYaGEGxm"
      },
      "outputs": [],
      "source": [
        "df=df[['Category','Cont']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=df"
      ],
      "metadata": {
        "id": "YRDOVqwxVngz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Value Count"
      ],
      "metadata": {
        "id": "iKb2xT3wIeO3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peE5eq1YEjTX"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_filtered = data.mask(lambda x: x['Category'] == 'Not-Tamil')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW6ndfZVEogG",
        "outputId": "e0ebea18-b68a-4b68-d574-996b0375e1dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "None-of-the-above    1296\n",
              "Misandry              446\n",
              "Counter-speech        149\n",
              "Misogyny              125\n",
              "Xenophobia             95\n",
              "Hope-Speech            85\n",
              "Homophobia             35\n",
              "Transphobic             6\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df_filtered['Category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUy_sZ8CE8Ey"
      },
      "outputs": [],
      "source": [
        "data_train=data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Text Import"
      ],
      "metadata": {
        "id": "SQs23R-rImB8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiQaAGr0GO5X",
        "outputId": "23ab7136-a05a-44e4-8c46-71834dff097e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting clean-text\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting emoji<2.0.0,>=1.0.0 (from clean-text)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.6)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=be87220cdefe2cf41e54629d33c94ef5d92aeb00c2f79b3d0b59b10b63cf2866\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, ftfy, clean-text\n",
            "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.1.1\n"
          ]
        }
      ],
      "source": [
        "pip install clean-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INcoTxMnGXt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c27166f-e3c6-4c6a-8697-6fb667e80d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ]
        }
      ],
      "source": [
        "from cleantext import clean\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "Bev9fiIlJSJX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kG1a_RvVFJVd",
        "outputId": "a8ed8e06-1c9c-403f-abaa-11a88f4e8dd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Category                                               Cont  \\\n",
              "0  None-of-the-above  எச். ராசாவால் இராமருக்கே  இழிவு. இவர் எல்லாம் ...   \n",
              "1  None-of-the-above  கல்யாணம்னு  வரும்போது தான் சாதி முக்கியம் எங்க...   \n",
              "2  None-of-the-above                 Tentu Kottai ஐயா நான் தமிழ் இந்து.   \n",
              "3         Homophobia  Tamil selvan  அடே தேவடியாவுக்கு பிரந்தவனே பச்ச...   \n",
              "4  None-of-the-above  bro நீங்க பேசறதெல்லாம் கேக்க கேக்க இரவு துக்கம...   \n",
              "\n",
              "                               clean  \n",
              "0                              . . .  \n",
              "1                                     \n",
              "2                     tentu kottai .  \n",
              "3  tamil selvan ... . tamil selva...  \n",
              "4                                bro  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-041fcd18-2ef9-4904-b1f7-04af512b84f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Cont</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None-of-the-above</td>\n",
              "      <td>எச். ராசாவால் இராமருக்கே  இழிவு. இவர் எல்லாம் ...</td>\n",
              "      <td>. . .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None-of-the-above</td>\n",
              "      <td>கல்யாணம்னு  வரும்போது தான் சாதி முக்கியம் எங்க...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None-of-the-above</td>\n",
              "      <td>Tentu Kottai ஐயா நான் தமிழ் இந்து.</td>\n",
              "      <td>tentu kottai .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Homophobia</td>\n",
              "      <td>Tamil selvan  அடே தேவடியாவுக்கு பிரந்தவனே பச்ச...</td>\n",
              "      <td>tamil selvan ... . tamil selva...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None-of-the-above</td>\n",
              "      <td>bro நீங்க பேசறதெல்லாம் கேக்க கேக்க இரவு துக்கம...</td>\n",
              "      <td>bro</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-041fcd18-2ef9-4904-b1f7-04af512b84f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-041fcd18-2ef9-4904-b1f7-04af512b84f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-041fcd18-2ef9-4904-b1f7-04af512b84f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "data['clean'] = df_filtered['Cont'].apply(lambda x:clean(x))\n",
        "data.head()\n",
        "\n",
        "\n",
        "dev['clean'] = dev['Cont'].apply(lambda x:clean(x))\n",
        "dev.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3w3SampG4Uc",
        "outputId": "2691d966-3372-4842-9863-3c94a02417ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'None-of-the-above',\n",
              " 1: 'Homophobia',\n",
              " 2: 'Misandry',\n",
              " 3: 'Counter-speech',\n",
              " 4: 'Misogyny',\n",
              " 5: 'Xenophobia',\n",
              " 6: 'Transphobic',\n",
              " 7: 'Hope-Speech'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "y_train=data['Category']\n",
        "y_train=df_filtered['Category']\n",
        "y_test=dev['Category']\n",
        "\n",
        "\n",
        "y = pd.get_dummies(df_filtered['Category']).values\n",
        "\n",
        "\n",
        "y_train1=pd.get_dummies(y_train).values\n",
        "y_test1=pd.get_dummies(y_test).values\n",
        "diz_label = {}\n",
        "for i,Category in enumerate(df_filtered.Category.factorize()[1]):\n",
        "    diz_label[i] = Category\n",
        "\n",
        "diz_label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing"
      ],
      "metadata": {
        "id": "Ic2rPEJ0JiP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Transformer"
      ],
      "metadata": {
        "id": "7zCVJBj1KbCV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glNG2WU_HUS0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "cv_vect= count_vect.fit(data[\"clean\"])\n",
        "cv_vect_train= count_vect.transform(data[\"clean\"])\n",
        "cv_vect_test= count_vect.transform(dev[\"clean\"])\n",
        "\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_tfidf = tfidf_transformer.fit(cv_vect_train)\n",
        "X_tfidf_train = tfidf_transformer.transform(cv_vect_train)\n",
        "X_tfidf_test = tfidf_transformer.transform(cv_vect_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE Over Sampling"
      ],
      "metadata": {
        "id": "n_HjRV6xJw3F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX16ZHUpHrUv",
        "outputId": "74d24ba7-b9e3-47d8-e1e1-e27a1dbb8dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (3720) in class 0 will be larger than the number of samples in the majority class (class #5 -> 1296)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (3720) in class 1 will be larger than the number of samples in the majority class (class #5 -> 1296)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (3720) in class 2 will be larger than the number of samples in the majority class (class #5 -> 1296)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (3720) in class 3 will be larger than the number of samples in the majority class (class #5 -> 1296)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (3720) in class 4 will be larger than the number of samples in the majority class (class #5 -> 1296)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (3720) in class 5 will be larger than the number of samples in the majority class (class #5 -> 1296)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (37200) in class 6 will be larger than the number of samples in the majority class (class #5 -> 1296)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (3720) in class 7 will be larger than the number of samples in the majority class (class #5 -> 1296)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "\n",
        "strategy = {0:3720, 1:3720, 2:3720, 3:3720, 4:3720, 5:3720,6:37200,7:3720}\n",
        "oversample = SMOTE(sampling_strategy=strategy)\n",
        "X_train, y_train = oversample.fit_resample(X_tfidf_train, y_train1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "viQXfSSYJ151"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP Classifier"
      ],
      "metadata": {
        "id": "twcIzinLJ7nu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Classifier 2"
      ],
      "metadata": {
        "id": "5nWqnaNmbSDa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8LagbPt2ud0"
      },
      "outputs": [],
      "source": [
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3))\n",
        "tfidf_vect_ngram_chars.fit(data['Cont'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(data['Cont'])\n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(dev['Cont'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP classifier"
      ],
      "metadata": {
        "id": "8dzq5EzvammG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZMV0PO3Pbj5",
        "outputId": "e3e1fdc4-04e0-4f38-9f24-b1f326b27153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:558: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.27      0.43        33\n",
            "           1       0.88      0.78      0.82         9\n",
            "           2       1.00      0.38      0.55        24\n",
            "           3       0.90      0.24      0.38       116\n",
            "           4       0.80      0.15      0.25        27\n",
            "           5       0.71      0.98      0.82       328\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       1.00      0.40      0.57        20\n",
            "\n",
            "   micro avg       0.74      0.70      0.72       559\n",
            "   macro avg       0.91      0.52      0.60       559\n",
            "weighted avg       0.80      0.70      0.66       559\n",
            " samples avg       0.69      0.70      0.70       559\n",
            "\n",
            "[[ 13   0   0   0   0  20   0   0]\n",
            " [  1   7   0   0   0   1   0   0]\n",
            " [  3   0   9   0   0  12   0   0]\n",
            " [ 15   0   0  28   1  72   0   0]\n",
            " [  4   1   0   0   4  18   0   0]\n",
            " [  4   0   0   2   0 322   0   0]\n",
            " [  0   0   0   0   0   0   2   0]\n",
            " [  2   0   0   1   0  10   0   7]]\n",
            "Test Accuracy: 69.4097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# with char n_gram\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(data['clean'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(data['clean'])\n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(dev['clean'])\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp=MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300,activation = 'relu',solver='adam',random_state=1)\n",
        "mlp.fit(xtrain_tfidf_ngram_chars,y_train1)\n",
        "y_pred7=mlp.predict(xvalid_tfidf_ngram_chars)\n",
        "\n",
        "print(classification_report(y_test1, y_pred7))\n",
        "print(confusion_matrix(np.argmax(y_test1,axis=1),np.argmax(y_pred7,axis=1)))\n",
        "accuracy = accuracy_score(y_test1, y_pred7)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOooX3huPex4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70ee4a1-0899-41ef-a2e0-2bb1aa1873df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp=MLPClassifier()\n",
        "mlp.fit(X_tfidf_train,y_train1)\n",
        "y_pred=mlp.predict(X_tfidf_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test1, y_pred))\n",
        "print(confusion_matrix(np.argmax(y_test1,axis=1),np.argmax(y_pred,axis=1)))\n",
        "accuracy = accuracy_score(y_test1, y_pred)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeGRYjJ1ewCG",
        "outputId": "1c5b552e-8d7b-405c-928e-3aaf9448acc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.09      0.17        33\n",
            "           1       1.00      0.11      0.20         9\n",
            "           2       1.00      0.04      0.08        24\n",
            "           3       1.00      0.09      0.16       116\n",
            "           4       0.67      0.07      0.13        27\n",
            "           5       0.63      0.98      0.77       328\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.80      0.20      0.32        20\n",
            "\n",
            "   micro avg       0.64      0.61      0.63       559\n",
            "   macro avg       0.76      0.20      0.23       559\n",
            "weighted avg       0.75      0.61      0.52       559\n",
            " samples avg       0.61      0.61      0.61       559\n",
            "\n",
            "[[  3   0   0   0   0  30   0   0]\n",
            " [  3   1   0   0   0   5   0   0]\n",
            " [  0   0   1   0   0  23   0   0]\n",
            " [  7   0   0  10   1  98   0   0]\n",
            " [  6   0   0   0   2  19   0   0]\n",
            " [  5   0   0   0   0 322   0   1]\n",
            " [  1   0   0   0   0   1   0   0]\n",
            " [  1   0   0   0   0  15   0   4]]\n",
            "Test Accuracy: 61.3596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9XhW3aF3-9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7cb01f-c653-4c9f-ae93-505b924503f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 61.3596\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian NB"
      ],
      "metadata": {
        "id": "0rY083_AbHne"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv7UY3OO3z1N"
      },
      "outputs": [],
      "source": [
        "classifier = MajorityVotingClassifier(\n",
        "    clusterer = FixedLabelSpaceClusterer(clusters = [[1,2,3], [0, 2, 5], [4, 5]]),\n",
        "    classifier = ClassifierChain(classifier=GaussianNB())\n",
        ")\n",
        "classifier.fit(xtrain_tfidf_ngram_chars,y_train1)\n",
        "y_pred_m=classifier.predict(xvalid_tfidf_ngram_chars)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test1, y_pred_m))\n",
        "accuracy = accuracy_score(y_test1, y_pred_m)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz3YSH_N62zx",
        "outputId": "93d67897-f9b5-455e-e7bd-d1b216e8ef5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      1.00      0.15        33\n",
            "           1       0.02      1.00      0.05         9\n",
            "           2       0.69      0.38      0.49        24\n",
            "           3       0.53      0.23      0.32       116\n",
            "           4       0.07      1.00      0.13        27\n",
            "           5       1.00      0.26      0.41       328\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00        20\n",
            "\n",
            "   micro avg       0.14      0.34      0.20       559\n",
            "   macro avg       0.30      0.48      0.19       559\n",
            "weighted avg       0.73      0.34      0.35       559\n",
            " samples avg       0.27      0.34      0.29       559\n",
            "\n",
            "Test Accuracy: 22.5403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "9VTKP7RwaZ4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "5UCX8miNaTVE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-UaP1FTUV3T"
      },
      "outputs": [],
      "source": [
        "X_train=data['clean'].tolist()\n",
        "X_test =dev['clean'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgCyDH9paQ2y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcpK3nCuWpd9"
      },
      "outputs": [],
      "source": [
        "vocabulary_size = 25000\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_train1 = pad_sequences(sequences, maxlen=500)\n",
        "sequences = tokenizer.texts_to_sequences(X_test)\n",
        "X_test1 = pad_sequences(sequences, maxlen=500)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaZkVYs6Xnu_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpfUr_QRXdQu"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(20000, 1000, input_length=500))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(64, 2, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(8, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlhWGRQ7YYY6"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxSa48jwYh5c"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DJGsV9rYk52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bcfda0f-f757-460c-edc3-91c805648394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 44s 5s/step - loss: 1.7089 - accuracy: 0.5151 - val_loss: 1.4967 - val_accuracy: 0.5580\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.3790 - accuracy: 0.5811 - val_loss: 1.3330 - val_accuracy: 0.5580\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 35s 4s/step - loss: 1.3313 - accuracy: 0.5811 - val_loss: 1.3490 - val_accuracy: 0.5580\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.3250 - accuracy: 0.5811 - val_loss: 1.3095 - val_accuracy: 0.5580\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.3161 - accuracy: 0.5811 - val_loss: 1.3151 - val_accuracy: 0.5580\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.3114 - accuracy: 0.5811 - val_loss: 1.3066 - val_accuracy: 0.5580\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 35s 4s/step - loss: 1.3044 - accuracy: 0.5811 - val_loss: 1.3087 - val_accuracy: 0.5580\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.2927 - accuracy: 0.5811 - val_loss: 1.2969 - val_accuracy: 0.5580\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.2770 - accuracy: 0.5816 - val_loss: 1.2974 - val_accuracy: 0.5580\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.2547 - accuracy: 0.5866 - val_loss: 1.2892 - val_accuracy: 0.5580\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.2342 - accuracy: 0.5940 - val_loss: 1.2865 - val_accuracy: 0.5580\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 35s 4s/step - loss: 1.2172 - accuracy: 0.6000 - val_loss: 1.2894 - val_accuracy: 0.5580\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.2011 - accuracy: 0.6040 - val_loss: 1.2855 - val_accuracy: 0.5536\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 35s 4s/step - loss: 1.1855 - accuracy: 0.6094 - val_loss: 1.2947 - val_accuracy: 0.5536\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.1697 - accuracy: 0.6154 - val_loss: 1.3041 - val_accuracy: 0.5491\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 35s 4s/step - loss: 1.1545 - accuracy: 0.6199 - val_loss: 1.3124 - val_accuracy: 0.5491\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.1462 - accuracy: 0.6208 - val_loss: 1.3234 - val_accuracy: 0.5446\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.1361 - accuracy: 0.6238 - val_loss: 1.3242 - val_accuracy: 0.5446\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 35s 4s/step - loss: 1.1279 - accuracy: 0.6238 - val_loss: 1.3253 - val_accuracy: 0.5491\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 34s 4s/step - loss: 1.1231 - accuracy: 0.6273 - val_loss: 1.3322 - val_accuracy: 0.5536\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd27f7b8370>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "model.fit(X_train1, y_train1,batch_size=254,epochs=20,verbose=1,validation_split=0.1,)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ7no7rbwMJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bbb14e-79e9-4ca5-a8e7-79cc4b731594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 3s 122ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoxoTkhcvzUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a6e88c2-5841-472a-9b52-07ad293df86e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.09      0.17        33\n",
            "           1       0.50      0.11      0.18         9\n",
            "           2       1.00      0.08      0.15        24\n",
            "           3       0.64      0.06      0.11       116\n",
            "           4       0.45      0.19      0.26        27\n",
            "           5       0.62      0.99      0.76       328\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.50      0.25      0.33        20\n",
            "\n",
            "    accuracy                           0.62       559\n",
            "   macro avg       0.59      0.22      0.25       559\n",
            "weighted avg       0.65      0.62      0.52       559\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "prediction_num= np.argmax(preds,axis=1)\n",
        "pred=np.argmax(preds,axis=1)\n",
        "print(classification_report(np.argmax(y_test1,axis=1),np.argmax(preds,axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqB-kdRBwCLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8dbea4-8fb2-4eff-8230-d8382ad80e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  3   0   0   0   0  30   0   0]\n",
            " [  0   1   0   0   3   5   0   0]\n",
            " [  0   0   2   1   0  21   0   0]\n",
            " [  0   0   0   7   2 104   0   3]\n",
            " [  0   0   0   0   5  20   0   2]\n",
            " [  0   0   0   3   1 324   0   0]\n",
            " [  0   1   0   0   0   1   0   0]\n",
            " [  0   0   0   0   0  15   0   5]]\n"
          ]
        }
      ],
      "source": [
        "pred=np.argmax(preds,axis=1)\n",
        "print(confusion_matrix(np.argmax(y_test1,axis=1),np.argmax(preds,axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Machine Learning\n"
      ],
      "metadata": {
        "id": "my2lEiKp7JMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "RSr8X9D6Z-_H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xbi6y3KRLHof"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "model = tree.DecisionTreeClassifier()\n",
        "model.fit(xtrain_tfidf_ngram_chars,y_train1)\n",
        "y_pred_dt=model.predict(xvalid_tfidf_ngram_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWuI-mypLodV"
      },
      "outputs": [],
      "source": [
        "y_pred_9 =np.argmax(y_pred_dt,axis=1)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "label = le.fit(data['Category'])\n",
        "label_t=le.fit_transform(data['Category'])\n",
        "prediction9=le.inverse_transform(y_pred_9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVFlaRznKube",
        "outputId": "cd44a8fc-fcee-4bba-ad4c-3ec91d259c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.33      0.50        33\n",
            "           1       0.88      0.78      0.82         9\n",
            "           2       1.00      0.46      0.63        24\n",
            "           3       0.98      0.37      0.54       116\n",
            "           4       0.83      0.19      0.30        27\n",
            "           5       0.73      0.94      0.82       328\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       1.00      0.40      0.57        20\n",
            "\n",
            "   micro avg       0.77      0.71      0.74       559\n",
            "   macro avg       0.93      0.56      0.65       559\n",
            "weighted avg       0.83      0.71      0.70       559\n",
            " samples avg       0.71      0.71      0.71       559\n",
            "\n",
            "[[ 14   0   0   0   0  19   0   0]\n",
            " [  1   7   0   0   0   1   0   0]\n",
            " [  5   0  11   0   0   8   0   0]\n",
            " [  9   0   0  43   1  63   0   0]\n",
            " [  7   1   0   0   5  14   0   0]\n",
            " [ 19   0   0   1   0 308   0   0]\n",
            " [  0   0   0   0   0   0   2   0]\n",
            " [  4   0   0   0   0   8   0   8]]\n",
            "Test Accuracy: 70.6619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test1,y_pred_dt))\n",
        "print(confusion_matrix(y_test1.argmax(axis=1),y_pred_dt.argmax(axis=1)))\n",
        "accuracy = accuracy_score(y_test1, y_pred_dt)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-epERWEjtBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(xtrain_tfidf_ngram_chars,y_train1, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "lFqohSG4WeD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "6Wa05mdEZ2xr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wB1O9fgMrc6",
        "outputId": "019af179-8d76-49ae-fbc0-3de9d80f92cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.33      0.48        33\n",
            "           1       0.88      0.78      0.82         9\n",
            "           2       0.92      0.50      0.65        24\n",
            "           3       0.94      0.38      0.54       116\n",
            "           4       0.83      0.19      0.30        27\n",
            "           5       0.73      0.95      0.83       328\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       1.00      0.40      0.57        20\n",
            "\n",
            "   micro avg       0.77      0.72      0.74       559\n",
            "   macro avg       0.89      0.57      0.65       559\n",
            "weighted avg       0.81      0.72      0.70       559\n",
            " samples avg       0.72      0.72      0.72       559\n",
            "\n",
            "[[ 13   0   0   1   0  19   0   0]\n",
            " [  1   7   0   0   0   1   0   0]\n",
            " [  4   0  12   0   0   8   0   0]\n",
            " [  7   0   1  44   1  63   0   0]\n",
            " [  6   1   0   0   5  15   0   0]\n",
            " [ 16   0   0   1   0 311   0   0]\n",
            " [  0   0   0   0   0   0   2   0]\n",
            " [  3   0   0   1   0   8   0   8]]\n",
            "Test Accuracy: 71.5564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn import ensemble\n",
        "model = ensemble.RandomForestClassifier()\n",
        "model.fit(xtrain_tfidf_ngram_chars,y_train1)\n",
        "y_pred10=model.predict(xvalid_tfidf_ngram_chars)\n",
        "\n",
        "\n",
        "\n",
        "print(classification_report(y_test1,y_pred10))\n",
        "print(confusion_matrix(y_test1.argmax(axis=1),y_pred10.argmax(axis=1)))\n",
        "accuracy = accuracy_score(y_test1, y_pred10)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "2BHFX8SvZvKG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1NDpRuiNe_C",
        "outputId": "0f029a0a-69e4-4abc-e3c5-b7865fa80673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.09      0.17        33\n",
            "           1       0.75      0.33      0.46         9\n",
            "           2       0.00      0.00      0.00        24\n",
            "           3       0.67      0.12      0.20       116\n",
            "           4       0.50      0.11      0.18        27\n",
            "           5       0.67      0.94      0.78       328\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       1.00      0.05      0.10        20\n",
            "\n",
            "   micro avg       0.67      0.59      0.63       559\n",
            "   macro avg       0.57      0.21      0.24       559\n",
            "weighted avg       0.66      0.59      0.53       559\n",
            " samples avg       0.59      0.59      0.59       559\n",
            "\n",
            "[[ 11   0   0   1   0  21   0   0]\n",
            " [  3   3   0   0   1   2   0   0]\n",
            " [  7   0   0   0   0  17   0   0]\n",
            " [ 19   0   0  14   2  81   0   0]\n",
            " [  6   1   0   0   3  17   0   0]\n",
            " [ 17   0   0   4   0 307   0   0]\n",
            " [  1   0   0   0   0   1   0   0]\n",
            " [  5   0   0   2   0  12   0   1]]\n",
            "Test Accuracy: 59.2129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn=KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(xtrain_tfidf_ngram_chars,y_train1)\n",
        "y_pred11=knn.predict(xvalid_tfidf_ngram_chars)\n",
        "\n",
        "\n",
        "print(classification_report(y_test1,y_pred11))\n",
        "print(confusion_matrix(y_test1.argmax(axis=1),y_pred11.argmax(axis=1)))\n",
        "accuracy = accuracy_score(y_test1, y_pred11)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvv5bklKP5RC"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBClassifier"
      ],
      "metadata": {
        "id": "1SGm9GAmZrCs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyn1mt1zOdEU",
        "outputId": "8b8e03f9-1b95-491a-ac73-b3b7e489acdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.33      0.50        33\n",
            "           1       0.88      0.78      0.82         9\n",
            "           2       1.00      0.38      0.55        24\n",
            "           3       0.93      0.33      0.48       116\n",
            "           4       0.83      0.19      0.30        27\n",
            "           5       0.72      0.95      0.82       328\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       1.00      0.40      0.57        20\n",
            "\n",
            "   micro avg       0.75      0.70      0.73       559\n",
            "   macro avg       0.92      0.54      0.63       559\n",
            "weighted avg       0.81      0.70      0.69       559\n",
            " samples avg       0.70      0.70      0.70       559\n",
            "\n",
            "[[ 14   0   0   0   0  19   0   0]\n",
            " [  1   7   0   0   0   1   0   0]\n",
            " [  3   0   9   0   0  12   0   0]\n",
            " [ 10   0   0  38   1  67   0   0]\n",
            " [  6   1   0   0   5  15   0   0]\n",
            " [ 13   0   0   2   0 313   0   0]\n",
            " [  0   0   0   0   0   0   2   0]\n",
            " [  3   0   0   1   0   8   0   8]]\n",
            "Test Accuracy: 69.9463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "xg=XGBClassifier()\n",
        "xg.fit(xtrain_tfidf_ngram_chars,y_train1)\n",
        "y_pred12=xg.predict(xvalid_tfidf_ngram_chars)\n",
        "\n",
        "\n",
        "print(classification_report(y_test1,y_pred12))\n",
        "print(confusion_matrix(y_test1.argmax(axis=1),y_pred12.argmax(axis=1)))\n",
        "accuracy = accuracy_score(y_test1, y_pred12)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def clean_dataset(data):\n",
        "    assert isinstance(data, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    data.dropna(inplace=True)\n",
        "    indices_to_keep = ~data.isin([np.nan, np.inf, -np.inf]).any(axis=1)\n",
        "    return data[indices_to_keep].astype(np.float64)"
      ],
      "metadata": {
        "id": "WnS9o4deFJcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=data['Category']\n",
        "x_test=dev['Cont']\n",
        "y_test=dev['Category']\n",
        "x_train=data['Cont'].astype(str)"
      ],
      "metadata": {
        "id": "oMs5CzKdAiaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect = CountVectorizer(ngram_range=(1, 2))\n",
        "transformer = TfidfTransformer(norm='l2',sublinear_tf=True)\n",
        "x_train_counts = count_vect.fit_transform(x_train)\n",
        "x_train_tfidf = transformer.fit_transform(x_train_counts)\n",
        "\n",
        "\n",
        "x_test_counts = count_vect.transform(x_test)\n",
        "x_test_tfidf = transformer.transform(x_test_counts)\n",
        "\n",
        "print (x_train_tfidf.shape,x_test_tfidf.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGr9F3kVBA1c",
        "outputId": "022d35b4-afb1-4fe6-c079-da00025cecba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2239, 14719) (559, 14719) (2239,) (559,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "data['label'] = le.fit_transform(data['Category'])"
      ],
      "metadata": {
        "id": "EeeGK6ljQ6ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_fit=data['label']"
      ],
      "metadata": {
        "id": "XjC4xZ5ZRgzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_fit_test=le.fit_transform(dev['Category'])"
      ],
      "metadata": {
        "id": "wfFPH2AOSWqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest"
      ],
      "metadata": {
        "id": "YkdDN5MtehKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(n_estimators=300, max_depth=15, random_state=42, class_weight='balanced')\n",
        "rfc.fit(x_train_tfidf,y_fit)\n",
        "y_pred4 = rfc.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_fit_test,y_pred4)))\n",
        "print(classification_report(y_fit_test, y_pred4))\n",
        "print(confusion_matrix(y_fit_test, y_pred4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OffOR_NB5YbA",
        "outputId": "a9b306cb-d943-466a-d064-6e5504c72920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8050089445438283\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.91      0.76        33\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       0.66      0.88      0.75        24\n",
            "           3       0.66      0.89      0.76       116\n",
            "           4       0.81      0.93      0.86        27\n",
            "           5       0.97      0.74      0.84       328\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       0.55      0.90      0.68        20\n",
            "\n",
            "    accuracy                           0.81       559\n",
            "   macro avg       0.79      0.90      0.83       559\n",
            "weighted avg       0.85      0.81      0.81       559\n",
            "\n",
            "[[ 30   0   0   1   0   2   0   0]\n",
            " [  0   9   0   0   0   0   0   0]\n",
            " [  0   0  21   1   0   2   0   0]\n",
            " [  4   0   1 103   3   3   0   2]\n",
            " [  0   0   0   1  25   1   0   0]\n",
            " [ 12   0  10  48   3 242   0  13]\n",
            " [  0   0   0   0   0   0   2   0]\n",
            " [  0   0   0   2   0   0   0  18]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "eyYAgC-bZYKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
        "lr.fit(x_train_tfidf, y_fit)\n",
        "y_pred1 = lr.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_fit_test,y_pred1)))\n",
        "print(classification_report(y_fit_test, y_pred1))\n",
        "print(confusion_matrix(y_fit_test, y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPL_WCt24x4C",
        "outputId": "6a8c561c-50ab-427b-c246-c3a674bec897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.853309481216458\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.61      0.74        33\n",
            "           1       1.00      0.67      0.80         9\n",
            "           2       1.00      0.08      0.15        24\n",
            "           3       0.94      0.88      0.91       116\n",
            "           4       0.91      0.37      0.53        27\n",
            "           5       0.81      0.99      0.89       328\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       1.00      0.60      0.75        20\n",
            "\n",
            "    accuracy                           0.85       559\n",
            "   macro avg       0.83      0.52      0.60       559\n",
            "weighted avg       0.87      0.85      0.83       559\n",
            "\n",
            "[[ 20   0   0   0   0  13   0   0]\n",
            " [  0   6   0   1   1   1   0   0]\n",
            " [  0   0   2   1   0  21   0   0]\n",
            " [  0   0   0 102   0  14   0   0]\n",
            " [  1   0   0   0  10  16   0   0]\n",
            " [  0   0   0   3   0 325   0   0]\n",
            " [  0   0   0   0   0   2   0   0]\n",
            " [  0   0   0   1   0   7   0  12]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVC"
      ],
      "metadata": {
        "id": "mg6y50wvZUU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "svc = LinearSVC()\n",
        "svc.fit(x_train_tfidf, y_fit)\n",
        "y_pred_svc = svc.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_fit_test,y_pred_svc)))\n",
        "print(classification_report(y_fit_test, y_pred_svc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOG6Miei45E9",
        "outputId": "a5963125-1d43-4b54-9247-e1713e9524f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9892665474060823\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      0.96      0.98        24\n",
            "           3       0.97      0.97      0.97       116\n",
            "           4       1.00      1.00      1.00        27\n",
            "           5       0.99      0.99      0.99       328\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           0.99       559\n",
            "   macro avg       1.00      0.99      0.99       559\n",
            "weighted avg       0.99      0.99      0.99       559\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_fit_test, y_pred_svc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGTqYWQqXHi2",
        "outputId": "4a082946-8593-4781-afb3-49f83196c1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  0   9   0   0   0   0   0   0]\n",
            " [  0   0  23   1   0   0   0   0]\n",
            " [  0   0   0 113   0   3   0   0]\n",
            " [  0   0   0   0  27   0   0   0]\n",
            " [  0   0   0   2   0 326   0   0]\n",
            " [  0   0   0   0   0   0   2   0]\n",
            " [  0   0   0   0   0   0   0  20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultinomialNB"
      ],
      "metadata": {
        "id": "i6-Y6drvZQM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(x_train_tfidf, y_fit)\n",
        "y_pred_mnb = mnb.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_fit_test,y_pred_mnb)))\n",
        "print(classification_report(y_fit_test, y_pred_mnb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqX7Xr6n5AMz",
        "outputId": "773241d6-af8e-44e1-d713-565fdcb3b1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6386404293381037\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        33\n",
            "           1       0.00      0.00      0.00         9\n",
            "           2       0.00      0.00      0.00        24\n",
            "           3       0.90      0.24      0.38       116\n",
            "           4       1.00      0.04      0.07        27\n",
            "           5       0.62      1.00      0.77       328\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.64       559\n",
            "   macro avg       0.32      0.16      0.15       559\n",
            "weighted avg       0.60      0.64      0.53       559\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_fit_test, y_pred_mnb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_C3KxF-XMCD",
        "outputId": "d341ed16-8503-406a-e79f-8b20b61d5beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0  33   0   0]\n",
            " [  0   0   0   1   0   8   0   0]\n",
            " [  0   0   0   0   0  24   0   0]\n",
            " [  0   0   0  28   0  88   0   0]\n",
            " [  0   0   0   1   1  25   0   0]\n",
            " [  0   0   0   0   0 328   0   0]\n",
            " [  0   0   0   0   0   2   0   0]\n",
            " [  0   0   0   1   0  19   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "_faC8LE3X8jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gbc = GradientBoostingClassifier(n_estimators=100, max_features='auto', max_depth=4, random_state=1, verbose=1)\n",
        "gbc.fit(x_train_tfidf, y_fit)\n",
        "y_pred_gbc = gbc.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_fit_test,y_pred_gbc)))\n",
        "print(classification_report(y_fit_test, y_pred_gbc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc_1C4fE5EDr",
        "outputId": "58d7a6f8-99ab-4e5f-8fa4-0045ccc9d706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1373            1.41m\n",
            "         2           1.0714            1.61m\n",
            "         3           1.0285            1.44m\n",
            "         4           0.9863            1.25m\n",
            "         5           0.9534            1.08m\n",
            "         6           0.9216           58.01s\n",
            "         7           0.8930           53.08s\n",
            "         8           0.8702           49.19s\n",
            "         9           0.8440           46.06s\n",
            "        10           0.8238           43.62s\n",
            "        20           0.6611           30.15s\n",
            "        30           0.5743           24.93s\n",
            "        40           0.5266           22.65s\n",
            "        50           0.4904           17.60s\n",
            "        60           0.4589           13.40s\n",
            "        70           0.4322            9.68s\n",
            "        80           0.4101            6.43s\n",
            "        90           0.3891            3.24s\n",
            "       100           0.3703            0.00s\n",
            "Accuracy: 0.9427549194991055\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      0.96      0.98        24\n",
            "           3       0.95      0.77      0.85       116\n",
            "           4       1.00      1.00      1.00        27\n",
            "           5       0.92      0.99      0.95       328\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           0.94       559\n",
            "   macro avg       0.98      0.96      0.97       559\n",
            "weighted avg       0.94      0.94      0.94       559\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_fit_test, y_pred_gbc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40tMlJOEXR0n",
        "outputId": "1621967e-32ce-4703-957b-d198d89b0273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  0   9   0   0   0   0   0   0]\n",
            " [  0   0  23   1   0   0   0   0]\n",
            " [  0   0   0  89   0  27   0   0]\n",
            " [  0   0   0   0  27   0   0   0]\n",
            " [  0   0   0   4   0 324   0   0]\n",
            " [  0   0   0   0   0   0   2   0]\n",
            " [  0   0   0   0   0   0   0  20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Classifier"
      ],
      "metadata": {
        "id": "JJJRMCiJfOaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnb = MultinomialNB()\n",
        "rfc= RandomForestClassifier(n_estimators=1000, max_depth=12, random_state=42)\n",
        "lr = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
        "svc = SVC(probability=True)\n",
        "ec=VotingClassifier(estimators=[('Multinominal NB', mnb), ('Random Forest', rfc),('Logistic Regression',lr),('Support Vector Machine',svc)], voting='soft', weights=[1,2,3,4])\n",
        "ec.fit(x_train_tfidf,y_fit)\n",
        "y_pred6 = ec.predict(x_test_tfidf)\n",
        "print(accuracy_score(y_fit_test, y_pred6))\n",
        "print(classification_report(y_fit_test, y_pred6))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eC_nFYM5PWD",
        "outputId": "dc1cff85-e72f-423d-8c2a-3d1175dda172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9767441860465116\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      0.96      0.98        24\n",
            "           3       0.96      0.92      0.94       116\n",
            "           4       1.00      1.00      1.00        27\n",
            "           5       0.97      0.99      0.98       328\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           0.98       559\n",
            "   macro avg       0.99      0.98      0.99       559\n",
            "weighted avg       0.98      0.98      0.98       559\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_fit_test, y_pred6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSAfe-wKXbdk",
        "outputId": "cb3b6e53-9e3c-4c77-d327-826a10b2b737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  0   9   0   0   0   0   0   0]\n",
            " [  0   0  23   1   0   0   0   0]\n",
            " [  0   0   0 107   0   9   0   0]\n",
            " [  0   0   0   0  27   0   0   0]\n",
            " [  0   0   0   3   0 325   0   0]\n",
            " [  0   0   0   0   0   0   2   0]\n",
            " [  0   0   0   0   0   0   0  20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AdaBoost"
      ],
      "metadata": {
        "id": "240i0t4-XpD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "abc= AdaBoostClassifier()\n",
        "\n",
        "abc.fit(x_train_tfidf,y_fit)\n",
        "y_pred_abc=abc.predict(x_test_tfidf)\n",
        "\n",
        "\n",
        "print(classification_report(y_fit_test,y_pred_abc))\n",
        "print(confusion_matrix(y_fit_test,y_pred_abc))\n",
        "accuracy = accuracy_score(y_fit_test, y_pred_abc)\n",
        "print(\"Test Accuracy:\", round(accuracy*100, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eum_XQ835jha",
        "outputId": "112d1889-be90-4548-ad96-88a473feaee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        33\n",
            "           1       0.54      0.78      0.64         9\n",
            "           2       0.00      0.00      0.00        24\n",
            "           3       0.65      0.32      0.43       116\n",
            "           4       0.00      0.00      0.00        27\n",
            "           5       0.64      0.96      0.77       328\n",
            "           6       1.00      0.50      0.67         2\n",
            "           7       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.64       559\n",
            "   macro avg       0.35      0.32      0.31       559\n",
            "weighted avg       0.52      0.64      0.55       559\n",
            "\n",
            "[[  0   0   0   1   0  32   0   0]\n",
            " [  0   7   0   1   0   1   0   0]\n",
            " [  0   0   0   1   0  23   0   0]\n",
            " [  0   3   0  37   0  76   0   0]\n",
            " [  0   1   0   0   0  26   0   0]\n",
            " [  0   0   0  14   0 314   0   0]\n",
            " [  0   0   0   0   0   1   1   0]\n",
            " [  0   2   0   3   0  15   0   0]]\n",
            "Test Accuracy: 64.2218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert Model\n"
      ],
      "metadata": {
        "id": "-jrIYr6rYpdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train=data['Cont'].astype(str)\n",
        "\n",
        "x_test=dev['Cont']\n",
        "\n",
        "X_train = x_train.tolist()\n",
        "X_test = x_test.tolist()\n",
        "y_train = y_fit.tolist()\n",
        "y_test = y_fit_test.tolist()"
      ],
      "metadata": {
        "id": "33sxkzWlY4Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['None-of-the-above','Homophobia','Misandry','Counter-speech','Misogyny','Xenophobia','Transphobic','Hope-Speech','Not-Tamil']"
      ],
      "metadata": {
        "id": "1bsRYGWW9pCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train), (x_val,y_val), preproc = text.texts_from_array(x_train=X_train, y_train=y_train,\n",
        "                                                                       x_test=X_test, y_test=y_test,\n",
        "                                                                       class_names=class_names,\n",
        "                                                                       preprocess_mode='bert',\n",
        "                                                                       maxlen=512,\n",
        "                                                                       max_features=20000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "QSMfkSoB-lt-",
        "outputId": "2ba155a8-bd0b-4bff-afc8-814d13d21f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading pretrained BERT model (multi_cased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: ta\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: ta\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "task: text classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = text.text_classifier('bert', train_data=(x_train,y_train), preproc=preproc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0BmdQmv-zcr",
        "outputId": "29ee511a-0ec4-49be-bc2f-e89808df54b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner = ktrain.get_learner(model, train_data=(x_train,y_train),\n",
        "                             val_data=(x_val,y_val),\n",
        "                             batch_size=6)\n"
      ],
      "metadata": {
        "id": "j1Ac-ZYO-55f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.fit_onecycle(2e-5, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMjK17Yf_Di4",
        "outputId": "eb2b2840-4e4c-4404-cf94-e348850a0a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/3\n",
            "374/374 [==============================] - 359s 894ms/step - loss: 1.3138 - accuracy: 0.5623 - val_loss: 1.0876 - val_accuracy: 0.6708\n",
            "Epoch 2/3\n",
            "374/374 [==============================] - 349s 934ms/step - loss: 1.0823 - accuracy: 0.6396 - val_loss: 0.9850 - val_accuracy: 0.6905\n",
            "Epoch 3/3\n",
            "374/374 [==============================] - 333s 890ms/step - loss: 0.8414 - accuracy: 0.7048 - val_loss: 0.7163 - val_accuracy: 0.7925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f21f2330520>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.validate(val_data=(x_val,y_val), class_names=class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhac6hcoDc81",
        "outputId": "910ebbc9-3cb0-4d02-accd-c0cacf32ea57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 28s 1s/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "None-of-the-above       0.48      0.36      0.41        33\n",
            "       Homophobia       1.00      0.56      0.71         9\n",
            "         Misandry       0.75      0.12      0.21        24\n",
            "   Counter-speech       0.80      0.90      0.85       116\n",
            "         Misogyny       0.54      0.26      0.35        27\n",
            "       Xenophobia       0.84      0.95      0.89       328\n",
            "      Transphobic       0.00      0.00      0.00         2\n",
            "      Hope-Speech       0.00      0.00      0.00        20\n",
            "        Not-Tamil       0.00      0.00      0.00         0\n",
            "\n",
            "         accuracy                           0.79       559\n",
            "        macro avg       0.49      0.35      0.38       559\n",
            "     weighted avg       0.76      0.79      0.76       559\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 12,   0,   1,   2,   1,  16,   0,   0,   1],\n",
              "       [  0,   5,   0,   3,   1,   0,   0,   0,   0],\n",
              "       [  1,   0,   3,   0,   0,  20,   0,   0,   0],\n",
              "       [  2,   0,   0, 104,   2,   8,   0,   0,   0],\n",
              "       [  4,   0,   0,   5,   7,  10,   0,   0,   1],\n",
              "       [  5,   0,   0,   8,   1, 312,   0,   0,   2],\n",
              "       [  0,   0,   0,   0,   1,   1,   0,   0,   0],\n",
              "       [  1,   0,   0,   8,   0,   6,   0,   0,   5],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}